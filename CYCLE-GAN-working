----------------first-working implementation , with all requirements included...........................

------------------cycle-gan-config-------------------

import torch
import torch.nn as nn
import functools

# --------------------------
# DEVICE
# --------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

##############################################
# Helper: Convolution Block
###############################################
def conv_block(in_channels, out_channels, kernel_size, stride, padding, norm=True):
    layers = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, bias=not norm)]
    if norm:
        layers.append(nn.InstanceNorm2d(out_channels))
    layers.append(nn.ReLU(inplace=True))
    return nn.Sequential(*layers)

###############################################
# ResNet Block
###############################################
class ResnetBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.block = nn.Sequential(
            nn.ReflectionPad2d(1),
            nn.Conv2d(dim, dim, kernel_size=3, padding=0),
            nn.InstanceNorm2d(dim),
            nn.ReLU(inplace=True),

            nn.ReflectionPad2d(1),
            nn.Conv2d(dim, dim, kernel_size=3, padding=0),
            nn.InstanceNorm2d(dim),
        )

    def forward(self, x):
        return x + self.block(x)  # skip connection

##############################################
# Generator: ResNet-based
###############################################
class ResnetGenerator(nn.Module):
    def __init__(self, input_nc=3, output_nc=3, ngf=64, n_blocks=6):
        super().__init__()

        # --- Encoder ---
        model = [
            nn.ReflectionPad2d(3),
            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0),
            nn.InstanceNorm2d(ngf),
            nn.ReLU(True)
        ]

        # Downsampling
        n_downsampling = 2
        for i in range(n_downsampling):
            mult = 2 ** i
            model += [
                nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),
                nn.InstanceNorm2d(ngf * mult * 2),
                nn.ReLU(True)
            ]

        # Transformer section: ResNet blocks
        mult = 2 ** n_downsampling
        for _ in range(n_blocks):
            model += [ResnetBlock(ngf * mult)]

        # Decoder
        for i in range(n_downsampling):
            mult = 2 ** (n_downsampling - i)
            model += [
                nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2),
                                   kernel_size=3, stride=2,
                                   padding=1, output_padding=1),
                nn.InstanceNorm2d(int(ngf * mult / 2)),
                nn.ReLU(True)
            ]

        # Output layer
        model += [
            nn.ReflectionPad2d(3),
            nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0),
            nn.Tanh()
        ]

        self.model = nn.Sequential(*model)

    def forward(self, x):
        return self.model(x)

###############################################
# 70x70 PatchGAN Discriminator
###############################################
class NLayerDiscriminator(nn.Module):
    def __init__(self, input_nc=3, ndf=64, n_layers=3):
        super().__init__()
        kw = 4
        padw = 1

        sequence = [
            nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw),
            nn.LeakyReLU(0.2, True)
        ]

        nf_mult = 1
        for n in range(1, n_layers):
            nf_mult_prev = nf_mult
            nf_mult = min(2 ** n, 8)
            sequence += [
                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw),
                nn.InstanceNorm2d(ndf * nf_mult),
                nn.LeakyReLU(0.2, True)
            ]

        sequence += [
            nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)
        ]

        self.model = nn.Sequential(*sequence)

    def forward(self, x):
        return self.model(x)

###############################################
# Instantiate models and move to device
###############################################
G = ResnetGenerator().to(device)
D = NLayerDiscriminator().to(device)

# Demo input tensor on device
x = torch.randn(1, 3, 256, 256, device=device)

fake = G(x)
disc = D(x)

print("Generator output shape:", fake.shape)
print("Discriminator output shape:", disc.shape)

---------------------------------------------------

----------------------loss calculation---------------------=

import torch
import torch.nn as nn

# --------------------------
# DEVICE
# --------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

###################################################
# LSGAN Loss (Least Squares GAN)
###################################################
class LSGANLoss(nn.Module):
    def __init__(self):
        super().__init__()
        self.loss = nn.MSELoss()

    def __call__(self, prediction, target_is_real):
        """target_is_real = True or False"""
        target = torch.ones_like(prediction, device=prediction.device) if target_is_real else torch.zeros_like(prediction, device=prediction.device)
        return self.loss(prediction, target)


###################################################
# CycleGAN Loss Wrapper
###################################################
# class CycleGANLoss:
#     def __init__(self, lambda_cycle=10.0, lambda_identity=5.0):
#         self.adv_loss = LSGANLoss()
#         self.cycle_loss_fn = nn.L1Loss()
#         self.id_loss_fn = nn.L1Loss()

#         self.lambda_cycle = lambda_cycle
#         self.lambda_identity = lambda_identity

#     def generator_loss(self, G, F, D_A, D_B, real_A, real_B):
#         ############################
#         # Adversarial Loss
#         ############################
#         fake_B = G(real_A)
#         pred_fake_B = D_B(fake_B)
#         loss_G_adv = self.adv_loss(pred_fake_B, True)

#         fake_A = F(real_B)
#         pred_fake_A = D_A(fake_A)
#         loss_F_adv = self.adv_loss(pred_fake_A, True)

#         ############################
#         # Cycle Consistency Loss
#         ############################
#         rec_A = F(fake_B)
#         loss_cycle_A = self.cycle_loss_fn(rec_A, real_A)

#         rec_B = G(fake_A)
#         loss_cycle_B = self.cycle_loss_fn(rec_B, real_B)

#         loss_cycle = loss_cycle_A + loss_cycle_B

#         ############################
#         # Identity Loss
#         ############################
       
#         with torch.no_grad():
#             id_B = G(real_B)
#             id_A = F(real_A)

#         loss_id_B = self.id_loss_fn(id_B, real_B)
#         loss_id_A = self.id_loss_fn(id_A, real_A)
#         loss_id = loss_id_A + loss_id_B

#         ############################
#         # Total Generator Loss
#         ############################
#         total_loss = (
#             loss_G_adv +
#             loss_F_adv +
#             self.lambda_cycle * loss_cycle +
#             self.lambda_identity * loss_id
#         )

#         return total_loss, {
#             "G_adv": loss_G_adv.item(),
#             "F_adv": loss_F_adv.item(),
#             "cycle": loss_cycle.item(),
#             "id": loss_id.item(),
#             "total": total_loss.item()
#         }

#     def discriminator_loss(self, D, real, fake):
#         pred_real = D(real)
#         loss_real = self.adv_loss(pred_real, True)

#         pred_fake = D(fake.detach())
#         loss_fake = self.adv_loss(pred_fake, False)

#         return (loss_real + loss_fake) * 0.5

class CycleGANLoss:
    def __init__(self, lambda_cycle=10.0, lambda_identity=5.0):
        self.adv_loss = LSGANLoss()
        self.cycle_loss_fn = nn.L1Loss()
        self.id_loss_fn = nn.L1Loss()

        self.lambda_cycle = lambda_cycle
        self.lambda_identity = lambda_identity

    def generator_loss(self, G, F, D_A, D_B, real_A, real_B):
        ############################
        # Adversarial Loss
        ############################
        fake_B = G(real_A)
        pred_fake_B = D_B(fake_B)
        loss_G_adv = self.adv_loss(pred_fake_B, True)

        fake_A = F(real_B)
        pred_fake_A = D_A(fake_A)
        loss_F_adv = self.adv_loss(pred_fake_A, True)

        ############################
        # Cycle Consistency Loss
        ############################
        # IMPORTANT FIXES:
        # detach BOTH fake_A and fake_B before feeding into cycle
        rec_A = F(fake_B.detach())     # FIXED
        loss_cycle_A = self.cycle_loss_fn(rec_A, real_A)

        rec_B = G(fake_A.detach())     # FIXED
        loss_cycle_B = self.cycle_loss_fn(rec_B, real_B)

        loss_cycle = loss_cycle_A + loss_cycle_B

        ############################
        # Identity Loss (no grad)
        ############################        
        with torch.no_grad():
            id_B = G(real_B)
            id_A = F(real_A)

        loss_id_B = self.id_loss_fn(id_B, real_B)
        loss_id_A = self.id_loss_fn(id_A, real_A)
        loss_id = loss_id_A + loss_id_B

        ############################
        # Total Generator Loss
        ############################
        total_loss = (
            loss_G_adv +
            loss_F_adv +
            self.lambda_cycle * loss_cycle +
            self.lambda_identity * loss_id
        )

        return total_loss, {
            "G_adv": loss_G_adv.item(),
            "F_adv": loss_F_adv.item(),
            "cycle": loss_cycle.item(),
            "id": loss_id.item(),
            "total": total_loss.item()
        }

    def discriminator_loss(self, D, real, fake):
        pred_real = D(real)
        loss_real = self.adv_loss(pred_real, True)

        pred_fake = D(fake.detach())
        loss_fake = self.adv_loss(pred_fake, False)

        return (loss_real + loss_fake) * 0.5


# --------------------------
# MODELS ON DEVICE
# --------------------------
G = ResnetGenerator().to(device)
F = ResnetGenerator().to(device)
D_A = NLayerDiscriminator().to(device)
D_B = NLayerDiscriminator().to(device)

loss_fn = CycleGANLoss()

# --------------------------
# DEMO INPUTS ON DEVICE
# --------------------------
real_A = torch.randn(1, 3, 256, 256, device=device)
real_B = torch.randn(1, 3, 256, 256, device=device)

# --------------------------
# GENERATOR LOSS
# --------------------------
G_loss, G_logs = loss_fn.generator_loss(G, F, D_A, D_B, real_A, real_B)
print("Generator Loss:", G_loss.item())
print(G_logs)

# --------------------------
# DISCRIMINATOR LOSSES
# --------------------------
fake_A = F(real_B)
fake_B = G(real_A)

D_A_loss = loss_fn.discriminator_loss(D_A, real_A, fake_A)
D_B_loss = loss_fn.discriminator_loss(D_B, real_B, fake_B)

print("D_A Loss:", D_A_loss.item())
print("D_B Loss:", D_B_loss.item())







---------------------------------------------------

--------------optimizer calculation----------------

import torch
import torch.nn as nn
import torch.optim as optim

# --------------------------
# DEVICE
# --------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# --------------------------
# STEP 2: Models
# --------------------------
# (Assume ResnetGenerator and NLayerDiscriminator classes are already defined)

G = ResnetGenerator().to(device)
F = ResnetGenerator().to(device)
D_A = NLayerDiscriminator().to(device)
D_B = NLayerDiscriminator().to(device)

# --------------------------
# STEP 3: Losses
# --------------------------
# (Assume CycleGANLoss class is already defined)
loss_fn = CycleGANLoss()

# --------------------------
# STEP 4: Optimizers + Scheduler
# --------------------------
lr = 2e-4
beta1 = 0.5
beta2 = 0.999
n_epochs = 100
n_epochs_decay = 100

optimizer_G = optim.Adam(list(G.parameters()) + list(F.parameters()), lr=lr, betas=(beta1, beta2))
optimizer_D_A = optim.Adam(D_A.parameters(), lr=lr, betas=(beta1, beta2))
optimizer_D_B = optim.Adam(D_B.parameters(), lr=lr, betas=(beta1, beta2))

def lambda_lr(epoch):
    if epoch < n_epochs:
        return 1.0
    else:
        return 1.0 - (epoch - n_epochs) / n_epochs_decay

scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_lr)
scheduler_D_A = optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_lr)
scheduler_D_B = optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_lr)

# --------------------------
# DEMO INPUTS (small batch) ON DEVICE
# --------------------------
real_A = torch.randn(2, 3, 256, 256).to(device)  # batch of 2
real_B = torch.randn(2, 3, 256, 256).to(device)

# --------------------------
# SINGLE TRAINING STEP
# --------------------------

# -- Generators update --
optimizer_G.zero_grad()
G_loss, G_logs = loss_fn.generator_loss(G, F, D_A, D_B, real_A, real_B)
G_loss = G_loss.to(device)  # ensure loss is on same device
G_loss.backward()
optimizer_G.step()

# -- Discriminators update --
optimizer_D_A.zero_grad()
fake_A = F(real_B)
fake_A = fake_A.to(device)
D_A_loss = loss_fn.discriminator_loss(D_A, real_A, fake_A)
D_A_loss = D_A_loss.to(device)
D_A_loss.backward()
optimizer_D_A.step()

optimizer_D_B.zero_grad()
fake_B = G(real_A)
fake_B = fake_B.to(device)
D_B_loss = loss_fn.discriminator_loss(D_B, real_B, fake_B)
D_B_loss = D_B_loss.to(device)
D_B_loss.backward()
optimizer_D_B.step()

# -- Step LR schedulers
scheduler_G.step()
scheduler_D_A.step()
scheduler_D_B.step()

# --------------------------
# PRINT RESULTS
# --------------------------
print("Generator Loss:", G_loss.item())
print("GEN Logs:", G_logs)
print("D_A Loss:", D_A_loss.item())
print("D_B Loss:", D_B_loss.item())
print("Current LR (G):", scheduler_G.get_last_lr()[0])

-----------------------------------------------


----------------image-pool-----------------------


import random
import torch

class ImagePool:
    """This class implements an image buffer that stores previously generated images."""
    def __init__(self, pool_size=50, device='cpu'):
        self.pool_size = pool_size
        self.images = []
        self.device = device

    def query(self, images):
        """
        Return images from buffer.
        50% chance to return old images from pool, otherwise return current images.
        """
        return_images = []
        for img in images:
            img = img.unsqueeze(0).to(self.device)  # ensure image is on correct device
            if len(self.images) < self.pool_size:
                # Fill pool until full
                self.images.append(img)
                return_images.append(img)
            else:
                if random.random() > 0.5:
                    # Use old image from pool
                    idx = random.randint(0, self.pool_size - 1)
                    tmp = self.images[idx].clone().to(self.device)
                    self.images[idx] = img
                    return_images.append(tmp)
                else:
                    # Use current image
                    return_images.append(img)
        return torch.cat(return_images, dim=0)

# --------------------------
# Create pools on the same device as models
# --------------------------
fake_A_pool = ImagePool(pool_size=50, device=device)
fake_B_pool = ImagePool(pool_size=50, device=device)

# --------------------------
# Generate new fake images
# --------------------------
fake_A = F(real_B)  # already on device
fake_B = G(real_A)

# Use image buffer for discriminator
fake_A_buffer = fake_A_pool.query(fake_A)
fake_B_buffer = fake_B_pool.query(fake_B)

# --------------------------
# Discriminator updates
# --------------------------
optimizer_D_A.zero_grad()
D_A_loss = loss_fn.discriminator_loss(D_A, real_A, fake_A_buffer)
D_A_loss = D_A_loss.to(device)  # ensure loss is on corre

--------------------------------------


-------------------training----------------


import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
import matplotlib.pyplot as plt

# --------------------------
# Hyperparameters
# -------------------------
n_epochs_demo = 35
batch_size = 2
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
image_size = 128

# --------------------------
# Custom Dataset (return tensors directly on device)
# --------------------------
class ImageFolderDataset(Dataset):
    def __init__(self, root_dir, transform=None, device='cpu'):
        self.files = sorted([os.path.join(root_dir, f) for f in os.listdir(root_dir) 
                             if f.endswith(".jpg") or f.endswith(".png")])
        self.transform = transform
        self.device = device

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        img = Image.open(self.files[idx]).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img.to(self.device)  # directly move to device

# --------------------------
# Transforms
# --------------------------
transform = transforms.Compose([
    transforms.Resize((image_size, image_size)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))
])

# --------------------------
# Load datasets
# --------------------------
trainA_dir = "/kaggle/input/horse2zebra-dataset/trainA"
trainB_dir = "/kaggle/input/horse2zebra-dataset/trainB"
testA_dir = "/kaggle/input/horse2zebra-dataset/testA"
testB_dir = "/kaggle/input/horse2zebra-dataset/testB"

trainA_dataset = ImageFolderDataset(trainA_dir, transform, device=device)
trainB_dataset = ImageFolderDataset(trainB_dir, transform, device=device)
testA_dataset = ImageFolderDataset(testA_dir, transform, device=device)
testB_dataset = ImageFolderDataset(testB_dir, transform, device=device)

train_loader = list(zip(DataLoader(trainA_dataset, batch_size=batch_size, shuffle=True),
                        DataLoader(trainB_dataset, batch_size=batch_size, shuffle=True)))

# --------------------------
# Move models to device
# --------------------------
G.to(device)
F.to(device)
D_A.to(device)
D_B.to(device)

# --------------------------
# Step 6: Image Buffers (ensure buffer tensors are on correct device)
# --------------------------
class ImagePool:
    def __init__(self, pool_size=50, device='cpu'):
        self.pool_size = pool_size
        self.images = []
        self.device = device

    def query(self, images):
        return_images = []
        for img in images:
            img = img.unsqueeze(0).to(self.device)
            if len(self.images) < self.pool_size:
                self.images.append(img)
                return_images.append(img)
            else:
                if torch.rand(1).item() > 0.5:
                    idx = torch.randint(0, self.pool_size, (1,)).item()
                    tmp = self.images[idx].clone()
                    self.images[idx] = img
                    return_images.append(tmp)
                else:
                    return_images.append(img)
        return torch.cat(return_images, dim=0)

fake_A_pool = ImagePool(pool_size=50, device=device)
fake_B_pool = ImagePool(pool_size=50, device=device)

# --------------------------
# TRAINING LOOP
# --------------------------
for epoch in range(n_epochs_demo):
    print(f"Epoch [{epoch+1}/{n_epochs_demo}]")
    epoch_G, epoch_D_A, epoch_D_B = 0.0, 0.0, 0.0
    num_batches = 0


    
    for (real_A_batch, real_B_batch) in train_loader:
        num_batches += 1

        real_A = real_A_batch  # already on device
        real_B = real_B_batch

        # ---- Train Generators ----
        optimizer_G.zero_grad()
        G_loss, G_logs = loss_fn.generator_loss(G, F, D_A, D_B, real_A, real_B)
        G_loss.backward()
        optimizer_G.step()

        # ---- Train Discriminators ----
        fake_A = F(real_B)
        fake_B = G(real_A)
        fake_A_buffer = fake_A_pool.query(fake_A)
        fake_B_buffer = fake_B_pool.query(fake_B)

        optimizer_D_A.zero_grad()
        D_A_loss = loss_fn.discriminator_loss(D_A, real_A, fake_A_buffer)
        D_A_loss.backward()
        optimizer_D_A.step()

        optimizer_D_B.zero_grad()
        D_B_loss = loss_fn.discriminator_loss(D_B, real_B, fake_B_buffer)
        D_B_loss.backward()
        optimizer_D_B.step()
        epoch_G += G_loss.item()
        epoch_D_A += D_A_loss.item()
        epoch_D_B += D_B_loss.item()

        # print(f"G_loss={G_loss.item():.4f}, D_A_loss={D_A_loss.item():.4f}, D_B_loss={D_B_loss.item():.4f}")
    print(f"Epoch {epoch+1} Summary:")
    print(f"  Avg G_loss:   {epoch_G / num_batches:.4f}")
    print(f"  Avg D_A_loss: {epoch_D_A / num_batches:.4f}")
    print(f"  Avg D_B_loss: {epoch_D_B / num_batches:.4f}")


    scheduler_G.step()
    scheduler_D_A.step()
    scheduler_D_B.step()
    print(f"End of Epoch {epoch+1}, LR_G: {scheduler_G.get_last_lr()[0]:.6f}")

# --------------------------
# Save Model Weights
# --------------------------
torch.save(G.state_dict(), "G_weights.pth")
torch.save(F.state_dict(), "F_weights.pth")
torch.save(D_A.state_dict(), "D_A_weights.pth")
torch.save(D_B.state_dict(), "D_B_weights.pth")
print("Model weights saved!")

# --------------------------
# Test Generator on Demo Images
# --------------------------
def denormalize(tensor):
    return (tensor * 0.5 + 0.5).clamp(0,1)

G.eval()
F.eval()

with torch.no_grad():
    demo_imgs = torch.stack([testA_dataset[0], testA_dataset[1]]).to(device)
    fake_B = G(demo_imgs)

    for i in range(len(demo_imgs)):
        real_img = denormalize(demo_imgs[i].cpu()).permute(1,2,0).numpy()
        fake_img = denormalize(fake_B[i].cpu()).permute(1,2,0).numpy()

        plt.figure(figsize=(6,3))
        plt.subplot(1,2,1)
        plt.imshow(real_img)
        plt.title("Real A")
        plt.axis('off')

        plt.subplot(1,2,2)
        plt.imshow(fake_img)
        plt.title("Fake B")
        plt.axis('off')
        plt.show()

-----------------------------------





-------------------------------------------------------------------------------------------------------------


from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.initializers import RandomNormal
from tensorflow.keras.optimizers import Adam
import numpy as np
import matplotlib.pyplot as plt

# -----------------------------------------------------------
#  DISCRIMINATOR
# -----------------------------------------------------------
def define_discriminator(image_shape):
    init = RandomNormal(stddev=0.02)
    in_image = Input(shape=image_shape)

    d = Conv2D(64, (4,4), strides=(2,2), padding='same',
               kernel_initializer=init)(in_image)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(128, (4,4), strides=(2,2), padding='same',
               kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(256, (4,4), strides=(2,2), padding='same',
               kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(512, (4,4), strides=(2,2), padding='same',
               kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(512, (4,4), padding='same',
               kernel_initializer=init)(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    patch_out = Conv2D(1, (4,4), padding='same',
                       kernel_initializer=init)(d)

    model = Model(in_image, patch_out)
    model.compile(loss='mse',
                  optimizer=Adam(0.0002, beta_1=0.5),
                  loss_weights=[0.5])
    return model

# -----------------------------------------------------------
#  RESNET BLOCK
# -----------------------------------------------------------
def resnet_block(n_filters, input_layer):
    init = RandomNormal(stddev=0.02)

    g = Conv2D(n_filters, (3,3), padding='same',
               kernel_initializer=init)(input_layer)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    g = Conv2D(n_filters, (3,3), padding='same',
               kernel_initializer=init)(g)
    g = BatchNormalization()(g)

    g = Concatenate()([g, input_layer])
    return g

# -----------------------------------------------------------
#  GENERATOR
# -----------------------------------------------------------
def define_generator(image_shape, n_resnet=6):
    init = RandomNormal(stddev=0.02)
    in_image = Input(shape=image_shape)

    g = Conv2D(64, (7,7), padding='same',
               kernel_initializer=init)(in_image)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    g = Conv2D(128, (3,3), strides=(2,2), padding='same',
               kernel_initializer=init)(g)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    g = Conv2D(256, (3,3), strides=(2,2), padding='same',
               kernel_initializer=init)(g)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    for _ in range(n_resnet):
        g = resnet_block(256, g)

    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same',
                        kernel_initializer=init)(g)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same',
                        kernel_initializer=init)(g)
    g = BatchNormalization()(g)
    g = Activation('relu')(g)

    # output channels = 3 for RGB
    g = Conv2D(3, (7,7), padding='same',
               kernel_initializer=init)(g)
    g = BatchNormalization()(g)

    out_image = Activation('tanh')(g)

    return Model(in_image, out_image)

# -----------------------------------------------------------
#  COMPOSITE MODEL
# -----------------------------------------------------------
def define_composite_model(g1, d_model, g2, image_shape):
    g1.trainable = True
    d_model.trainable = False
    g2.trainable = False

    input_gen = Input(shape=image_shape)
    gen1_out = g1(input_gen)
    output_d = d_model(gen1_out)

    input_id = Input(shape=image_shape)
    output_id = g1(input_id)

    output_fwd = g2(gen1_out)
    gen2_out = g2(input_id)
    output_back = g1(gen2_out)

    model = Model([input_gen, input_id],
                  [output_d, output_id, output_fwd, output_back])

    model.compile(
        loss=['mse', 'mae', 'mae', 'mae'],
        loss_weights=[1, 5, 10, 10],
        optimizer=Adam(0.0002, beta_1=0.5)
    )
    return model

# -----------------------------------------------------------
#  TEST RANDOM RGB IMAGE
# -----------------------------------------------------------
image_shape = (28,28,3)
d = define_discriminator(image_shape)
gA = define_generator(image_shape)

x1 = np.random.uniform(-1,1,(1,28,28,3)).astype('float32')
x2 = np.random.uniform(-1,1,(1,28,28,3)).astype('float32')

fake_img = gA.predict(x1)
print("Random RGB input shape:", x1.shape)
print("Generated RGB output shape:", fake_img.shape)




import os
from tensorflow.keras.preprocessing.image import load_img, img_to_array

def load_images(path="", size=(28,28)):
    files = []
    folder = os.listdir(path)
    for f in folder:
        img = load_img(os.path.join(path, f), target_size=size)
        img = img_to_array(img)
        img = (img / 127.5) - 1.0
        files.append(img)
    return np.array(files)

print("Loading horse2zebra dataset...")
A = load_images("/kaggle/input/horse2zebra-dataset/trainA")   # horses
B = load_images("/kaggle/input/horse2zebra-dataset/trainB")   # zebras

print("Shape A:", A.shape)
print("Shape B:", B.shape)

image_shape = (28, 28, 3)





dA = define_discriminator(image_shape)
dB = define_discriminator(image_shape)

gA2B = define_generator(image_shape)
gB2A = define_generator(image_shape)

cA = define_composite_model(gA2B, dB, gB2A, image_shape)
cB = define_composite_model(gB2A, dA, gA2B, image_shape)

# ======================================================================
#                          TRAINING LOOP
# ======================================================================

epochs = 2
batch_size = 1
steps = min(len(A), len(B))
print(steps)

for epoch in range(epochs):
    for i in range(steps):

        # Real samples
        realA = A[i:i+1]
        realB = B[i:i+1]

        # Generate fake
        print(realA.shape)
        print(realB.shape)
        fakeB = gA2B.predict(realA)
        fakeA = gB2A.predict(realB)

        # Real labels = 1, Fake = 0
        y_real = np.ones((1,) + dA.output_shape[1:])
        y_fake = np.zeros((1,) + dA.output_shape[1:])

        # Train discriminators
        dA_loss_real = dA.train_on_batch(realA, y_real)
        dA_loss_fake = dA.train_on_batch(fakeA, y_fake)
        dB_loss_real = dB.train_on_batch(realB, y_real)
        dB_loss_fake = dB.train_on_batch(fakeB, y_fake)

        # Train generators (cycle losses)
        g_loss_A = cA.train_on_batch([realA, realA], 
                                     [y_real, realA, realA, realA])
        g_loss_B = cB.train_on_batch([realB, realB], 
                                     [y_real, realB, realB, realB])

    print(f"Epoch {epoch+1}/{epochs} completed.")

print("Training Finished.")

import matplotlib.pyplot as plt

# -----------------------------------------------------------
# TEST GENERATOR AFTER TRAINING
# -----------------------------------------------------------

# Take first 3 images from dataset A (dummy images)
test_images = A[:3]

# Generate fake images (A â†’ B)
generated_images = gA2B.predict(test_images)

# Visualize original and generated images
for i in range(len(test_images)):
    plt.figure(figsize=(4,2))
    
    # Original image
    plt.subplot(1,2,1)
    plt.title("Original A")
    plt.imshow((test_images[i] + 1)/2)  # scale back to [0,1] for visualization
    plt.axis('off')
    
    # Generated image
    plt.subplot(1,2,2)
    plt.title("Generated B")
    plt.imshow((generated_images[i] + 1)/2)
    plt.axis('off')
    
    plt.show()
