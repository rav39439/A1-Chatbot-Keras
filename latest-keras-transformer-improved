import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from collections import defaultdict
import string
import tensorflow as tf
import re
import os
import time
from tensorflow import keras
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
ENCODER_LEN = 64
DECODER_LEN = 256
BATCH_SIZE = 16
BUFFER_SIZE = BATCH_SIZE*8



df = pd.read_csv("/kaggle/input/193k-medium-articles-dataset-for-llm-finetuning/193k.csv")
news=df.head(200)
article = news['title']
summary = news['text']

# Add SOS and EOS tokens
article = article.apply(lambda x:str(x))
summary = summary.apply(lambda x: '<SOS> ' + str(x) + ' <EOS>')

def preprocess(text):
    # Tokenize numbers and separate them into digits
    text = re.sub(r'(\d+)', lambda match: ' '.join(list(match.group(0))), text)  # e.g., "64" â†’ "6 4"

    # Add spaces around operators for proper tokenization
    text = re.sub(r"(\+|\-|\*|/|=)", r" \1 ", text)  # Add spaces around operators

    # Tokenize spaces between words
    text = re.sub(r'\s+', ' ', text).strip()  # Normalize spaces

    # Make text lowercase
    text = text.lower()

    return text
# Apply preprocessing
article = article.apply(preprocess)
summary = summary.apply(preprocess)
# summary = summary.apply(lambda x: ' '.join(x.split()[:-3]))

filters = 'â‚¹!"#$%&()-.:;?@[\\]^_`{|}~\t\n,'  # Ensure ',' is inside the quotes

# filters = 'â‚¹!"#$%&(),-./:;=?@[\\]^_`{|}~\t\n'

oov_token = '<unk>'

article_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)
summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)

# Fit tokenizers on preprocessed data
article_tokenizer.fit_on_texts(article)
summary_tokenizer.fit_on_texts(summary)
if ',' not in article_tokenizer.word_index:
    article_tokenizer.word_index[','] = len(article_tokenizer.word_index) + 1

if ',' not in summary_tokenizer.word_index:
    summary_tokenizer.word_index[','] = len(summary_tokenizer.word_index) + 1
# Convert text to sequences
inputs = article_tokenizer.texts_to_sequences(article)
targets = summary_tokenizer.texts_to_sequences(summary)
# print(inputs)

# Vocabulary sizes
ENCODER_VOCAB = len(article_tokenizer.word_index) + 1
DECODER_VOCAB = len(summary_tokenizer.word_index) + 1
top_k=4
# Pad sequences
# ENCODER_LEN = 70  # Maximum length of input sequences
# DECODER_LEN = 40   # Maximum length of output sequences

inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')
targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')
input_texts_padded = [' '.join([article_tokenizer.index_word.get(token, '') for token in seq]) for seq in inputs]
target_texts_padded = [' '.join([summary_tokenizer.index_word.get(token, '') for token in seq]) for seq in targets]

# Print tokenizers' word index
# print("Article Tokenizer Word Index (Word to Token):")
# print(article_tokenizer.word_index)
# print("\nSummary Tokenizer Word Index (Word to Token):")
# print(summary_tokenizer.word_index)

inputs = tf.cast(inputs, dtype=tf.int64)
targets = tf.cast(targets, dtype=tf.int64)
dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)

import tensorflow as tf
from tensorflow.keras.layers import Dense, Layer, Dropout, LayerNormalization


class MoELayer(Layer):
    def __init__(self, d_model, d_ff, num_experts=4, top_k=2, dropout_rate=0.1):
        """
        d_model: Model embedding size
        d_ff: Hidden layer size for FFN
        num_experts: Number of expert FFNs
        top_k: Number of experts selected per token
        dropout_rate: Dropout rate for regularization
        """
        super(MoELayer, self).__init__()
        self.num_experts = num_experts
        self.top_k = top_k

        # Define multiple FFN experts
        self.experts = [Dense(d_ff, activation="relu") for _ in range(num_experts)]
        self.output_layer = Dense(d_model)  # Final projection back to d_model
        self.dropout = Dropout(dropout_rate)
        self.layer_norm = LayerNormalization()

        # Router to decide which experts to activate
        self.router = Dense(num_experts, activation="softmax")  # Output is routing weights

    def call(self, x):
        batch_size, seq_len, d_model = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]

        # Compute routing weights for each token
        routing_logits = self.router(x)  # Shape: (batch_size, seq_len, num_experts)

        # Select top-k experts based on highest routing weights
        top_k_values, top_k_indices = tf.math.top_k(routing_logits, k=self.top_k)  # (batch_size, seq_len, top_k)

        # Normalize routing weights (softmax over selected experts)
        routing_weights = tf.nn.softmax(top_k_values, axis=-1)  # (batch_size, seq_len, top_k)

        # Compute outputs from selected experts
        expert_outputs = tf.stack([self.experts[i](x) for i in range(self.num_experts)], axis=-1)
        # Shape: (batch_size, seq_len, d_ff, num_experts)

        # Gather selected experts' outputs
        selected_expert_outputs = tf.gather(expert_outputs, top_k_indices, batch_dims=-1, axis=-1)
        # Shape: (batch_size, seq_len, d_ff, top_k)

        # Weighted sum of top-k expert outputs
        weighted_expert_output = tf.reduce_sum(selected_expert_outputs * tf.expand_dims(routing_weights, -2), axis=-1)
        # Shape: (batch_size, seq_len, d_ff)

        # Final projection back to d_model
        output = self.output_layer(weighted_expert_output)
        return self.layer_norm(x + self.dropout(output))  # Residual connection

class SwitchLayer(tf.keras.layers.Layer):
    def __init__(self, num_experts, d_model):
        super(SwitchLayer, self).__init__()
        self.experts = [tf.keras.layers.Dense(d_model) for _ in range(num_experts)]

    def call(self, x):
        # Route based on some condition (e.g., token type)
        condition = tf.reduce_mean(x, axis=-1) > 0
        output = tf.where(condition[:, tf.newaxis], self.experts[0](x), self.experts[1](x))
        return output

#--------------------------------------------------------------------------------------

"""
## Implement a Transformer block layer
"""

# def get_angles(position, i, d_model):
#     angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
#     return position * angle_rates

# def positional_encoding(position, d_model):
#     angle_rads = get_angles(
#         np.arange(position)[:, np.newaxis],
#         np.arange(d_model)[np.newaxis, :],
#         d_model
#     )

#     angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])

#     angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])

#     pos_encoding = angle_rads[np.newaxis, ...]

#     return tf.cast(pos_encoding, dtype=tf.float32)

# def create_padding_mask(seq):
#     seq = tf.cast(tf.math.equal(seq, 0), tf.float32)
#     return seq[:, tf.newaxis, tf.newaxis, :]

# def create_look_ahead_mask(size):
#     mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)
#     return mask

# def scaled_dot_product_attention(q, k, v, mask):
#     matmul_qk = tf.matmul(q, k, transpose_b=True)

#     dk = tf.cast(tf.shape(k)[-1], tf.float32)
#     scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)
#     if mask is not None:
#         scaled_attention_logits += (mask * -1e9)

#     attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)

#     output = tf.matmul(attention_weights, v)
#     return output, attention_weights


# class MultiHeadAttention(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads):
#         super(MultiHeadAttention, self).__init__()
#         self.num_heads = num_heads
#         self.d_model = d_model

#         assert d_model % self.num_heads == 0

#         self.depth = d_model // self.num_heads

#         self.wq = tf.keras.layers.Dense(d_model)
#         self.wk = tf.keras.layers.Dense(d_model)
#         self.wv = tf.keras.layers.Dense(d_model)

#         self.dense = tf.keras.layers.Dense(d_model)

#     def split_heads(self, x, batch_size):
#         x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
#         return tf.transpose(x, perm=[0, 2, 1, 3])

#     def call(self, v, k, q, mask):
#         batch_size = tf.shape(q)[0]

#         q = self.wq(q)
#         k = self.wk(k)
#         v = self.wv(v)

#         q = self.split_heads(q, batch_size)
#         k = self.split_heads(k, batch_size)
#         v = self.split_heads(v, batch_size)

#         scaled_attention, attention_weights = scaled_dot_product_attention(
#             q, k, v, mask)
#         scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])

#         concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))
#         output = self.dense(concat_attention)
#         return output, attention_weights


# def point_wise_feed_forward_network(d_model, dff):
#     return tf.keras.Sequential([
#         tf.keras.layers.Dense(dff, activation='relu'),
#         tf.keras.layers.Dense(d_model)
#     ])

# #-------------------------------------changing for retentian--------------------------------

# class EncoderLayer(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads, dff, rate=0.1):
#         super(EncoderLayer, self).__init__()
#         self.mha = MultiHeadAttention(d_model, num_heads)
#         self.ffn = point_wise_feed_forward_network(d_model, dff)
#         # self.moe = MoELayer(d_model,dff, top_k)
#         self.switch = SwitchLayer(num_experts=2, d_model=d_model)
#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)

#         self.dropout1 = tf.keras.layers.Dropout(rate)
#         self.dropout2 = tf.keras.layers.Dropout(rate)
#     # @tf.function
#     def call(self, x, training, mask):
#         attn_output, _ = self.mha(x, x, x, mask)
#         attn_output = self.dropout1(attn_output, training=training)
#         out1 = self.layernorm1(x + attn_output)
#         ffn_output = self.ffn(out1)
#         # moe_output  = self.moe(out1)
#         combined_output = ffn_output
#         combined_output = self.dropout2(combined_output, training=training)
#         out2 = self.layernorm2(out1 + combined_output)

#         return out2

# class DecoderLayer(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads, dff, rate=0.1):
#         super(DecoderLayer, self).__init__()
#         self.mha1 = MultiHeadAttention(d_model, num_heads)
#         self.mha2 = MultiHeadAttention(d_model, num_heads)
#         # self.moe = MoELayer(num_experts,d_model, top_k)
#         # self.moe = MoELayer(d_model,dff, top_k)
#         self.ffn = point_wise_feed_forward_network(d_model, dff)
#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         # self.switch = SwitchLayer(num_experts=2, d_model=d_model)

#         self.dropout1 = tf.keras.layers.Dropout(rate)
#         self.dropout2 = tf.keras.layers.Dropout(rate)
#         self.dropout3 = tf.keras.layers.Dropout(rate)

#     # @tf.function
#     def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
#         attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)
#         attn1 = self.dropout1(attn1, training=training)
#         out1 = self.layernorm1(attn1 + x)
#         attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)
#         attn2 = self.dropout2(attn2, training=training)
#         out2 = self.layernorm2(attn2 + out1)
#         ffn_output = self.ffn(out2)
#         # moe_output = self.moe(out2)
#         combined_output = ffn_output
#         combined_output = self.dropout3(combined_output, training=training)
#         out3 = self.layernorm3(combined_output + out2)
#         return out3, attn_weights_block1, attn_weights_block2


# class Encoder(tf.keras.layers.Layer):
#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):
#         super(Encoder, self).__init__()

#         self.d_model = d_model
#         self.num_layers = num_layers

#         self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
#         self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)

#         self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]

#         self.dropout = tf.keras.layers.Dropout(rate)

#     # @tf.function
#     def call(self, x, training, mask):
#         seq_len = tf.shape(x)[1]
#         x = self.embedding(x)
#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
#         x += self.pos_encoding[:, :seq_len, :]
#         x = self.dropout(x, training=training)

#         for i in range(self.num_layers):
#             x = self.enc_layers[i](x, training=training, mask=mask)

#         return x


# class Decoder(tf.keras.layers.Layer):
#     def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):
#         super(Decoder, self).__init__()

#         self.d_model = d_model
#         self.num_layers = num_layers

#         self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)
#         self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)

#         self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]
#         self.dropout = tf.keras.layers.Dropout(rate)

#     # @tf.function
#     def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
#         seq_len = tf.shape(x)[1]
#         attention_weights = {}
#         x = self.embedding(x)
#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
#         x += self.pos_encoding[:, :seq_len, :]
#         x = self.dropout(x, training=training)
#         for i in range(self.num_layers):
#             x, block1, block2 = self.dec_layers[i](x, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)
#             attention_weights['decoder_layer{}_block1'.format(i + 1)] = block1
#             attention_weights['decoder_layer{}_block2'.format(i + 1)] = block2
#         return x, attention_weights

# class Transformer(tf.keras.Model):
#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input,
#                      pe_target, rate=0.1):
#         super(Transformer, self).__init__()
#         self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)
#         self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)
#         self.final_layer = tf.keras.layers.Dense(target_vocab_size)

#     def update_final_layer_weights(self, new_weights):

#         sample_input = tf.random.uniform((1, new_weights[0].shape[0]))
#         _ = self.final_layer(sample_input)

#         # âœ… Get current weights
#         old_weights = self.final_layer.get_weights()
#         print(f"Old Weights Shape: {[w.shape for w in old_weights]}")

#         # âœ… Update weights
#         if len(new_weights) == 2:
#             self.final_layer.set_weights(new_weights)
#             print("âœ… Final layer weights updated successfully!")
#         else:
#             raise ValueError("New weights must be a list of [kernel, bias]")


#         # print(f"Updated Weights Shape: {[w.shape for w in updated_weights]}")

#     # @tf.function
#     def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):
#         enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)
#         dec_output, attention_weights = self.decoder(tar, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)
#         final_output = self.final_layer(dec_output)
#         return final_output, attention_weights

def create_cross_attention_mask(enc_padding_mask=None, dec_seq_len=None):
    """
    enc_padding_mask: [batch, 1, 1, enc_seq_len]
    dec_seq_len: scalar (length of decoder sequence)
    
    returns: cross_mask of shape [batch, 1, dec_seq_len, enc_seq_len]
    """
    if enc_padding_mask is None:
        return None
    
    # Tile encoder padding mask along decoder sequence length
    cross_mask = tf.tile(enc_padding_mask, [1, 1, dec_seq_len, 1])
    return cross_mask


def get_angles(position, i, d_model):
    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
    return position * angle_rates


def positional_encoding(position, d_model):
    angle_rads = get_angles(
        np.arange(position)[:, np.newaxis],
        np.arange(d_model)[np.newaxis, :],
        d_model
    )

    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])

    pos_encoding = angle_rads[np.newaxis, ...]
    return tf.cast(pos_encoding, dtype=tf.float32)


def create_padding_mask(seq):
    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)
    return seq[:, tf.newaxis, tf.newaxis, :]


def create_look_ahead_mask(size):
    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)
    return mask


def scaled_dot_product_attention(q, k, v, mask):
    matmul_qk = tf.matmul(q, k, transpose_b=True)
    dk = tf.cast(tf.shape(k)[-1], tf.float32)
    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)
    if mask is not None:
        scaled_attention_logits += (mask * -1e9)
    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
    output = tf.matmul(attention_weights, v)
    return output, attention_weights


class MultiHeadAttention(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads):
        super().__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        assert d_model % num_heads == 0
        self.depth = d_model // num_heads

        self.wq = tf.keras.layers.Dense(d_model)
        self.wk = tf.keras.layers.Dense(d_model)
        self.wv = tf.keras.layers.Dense(d_model)
        self.dense = tf.keras.layers.Dense(d_model)

    def split_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
        return tf.transpose(x, perm=[0, 2, 1, 3])

    def call(self, v, k, q, mask=None, **kwargs):
        batch_size = tf.shape(q)[0]
        q = self.wq(q)
        k = self.wk(k)
        v = self.wv(v)
        q = self.split_heads(q, batch_size)
        k = self.split_heads(k, batch_size)
        v = self.split_heads(v, batch_size)

        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)
        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])
        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))
        output = self.dense(concat_attention)
        return output, attention_weights


def point_wise_feed_forward_network(d_model, dff):
    return tf.keras.Sequential([
        tf.keras.layers.Dense(dff, activation='relu'),
        tf.keras.layers.Dense(d_model)
    ])


class EncoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super().__init__()
        self.mha = MultiHeadAttention(d_model, num_heads)
        self.ffn = point_wise_feed_forward_network(d_model, dff)
        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)

    def call(self, x, training=False, mask=None, **kwargs):
        attn_output, _ = self.mha(x, x, x, mask)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(x + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        out2 = self.layernorm2(out1 + ffn_output)
        return out2


class DecoderLayer(tf.keras.layers.Layer):
    def __init__(self, d_model, num_heads, dff, rate=0.1):
        super().__init__()
        self.mha1 = MultiHeadAttention(d_model, num_heads)
        self.mha2 = MultiHeadAttention(d_model, num_heads)
        self.ffn = point_wise_feed_forward_network(d_model, dff)
        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)
        self.dropout3 = tf.keras.layers.Dropout(rate)

    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None, **kwargs):
        
        
        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)
        attn1 = self.dropout1(attn1, training=training)
        out1 = self.layernorm1(x + attn1)
        # if padding_mask is not None:
        #   dec_seq_len = tf.shape(out1)[1]
        #   padding_mask = tf.tile(padding_mask, [1, 1, dec_seq_len, 1])
        dec_seq_len = tf.shape(out1)[1]
        cross_mask = create_cross_attention_mask(enc_padding_mask=padding_mask, dec_seq_len=dec_seq_len)

        # print(cross_mask)
        print(cross_mask)


        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, cross_mask)
        attn2 = self.dropout2(attn2, training=training)
        out2 = self.layernorm2(out1 + attn2)

        ffn_output = self.ffn(out2)
        ffn_output = self.dropout3(ffn_output, training=training)
        out3 = self.layernorm3(out2 + ffn_output)
        return out3, attn_weights_block1, attn_weights_block2


class Encoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,
                 maximum_position_encoding, rate=0.1):
        super().__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)
        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)
                           for _ in range(num_layers)]
        self.dropout = tf.keras.layers.Dropout(rate)

    def call(self, x, training=False, mask=None, **kwargs):
        seq_len = tf.shape(x)[1]
        x = self.embedding(x)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        x += self.pos_encoding[:, :seq_len, :]
        x = self.dropout(x, training=training)
        for i in range(self.num_layers):
            x = self.enc_layers[i](x, training=training, mask=mask)
        return x

class Decoder(tf.keras.layers.Layer):
    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,
                 maximum_position_encoding, rate=0.1):
        super().__init__()
        self.d_model = d_model
        self.num_layers = num_layers
        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)
        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)
        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate)
                           for _ in range(num_layers)]
        self.dropout = tf.keras.layers.Dropout(rate)

    def call(self, x, enc_output, training=False, look_ahead_mask=None, padding_mask=None, **kwargs):
        seq_len = tf.shape(x)[1]
        attention_weights = {}
        x = self.embedding(x)
        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
        x += self.pos_encoding[:, :seq_len, :]
        x = self.dropout(x, training=training)

        for i in range(self.num_layers):
            x, block1, block2 = self.dec_layers[i](
                x, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask
            )
            attention_weights[f'decoder_layer{i + 1}_block1'] = block1
            attention_weights[f'decoder_layer{i + 1}_block2'] = block2

        return x, attention_weights


class Transformer(tf.keras.Model):
    def __init__(self, num_layers, d_model, num_heads, dff,
                 input_vocab_size, target_vocab_size,
                 pe_input, pe_target, rate=0.1):
        super().__init__()
        self.encoder = Encoder(num_layers, d_model, num_heads, dff,
                               input_vocab_size, pe_input, rate)
        self.decoder = Decoder(num_layers, d_model, num_heads, dff,
                               target_vocab_size, pe_target, rate)
        self.final_layer = tf.keras.layers.Dense(target_vocab_size)

    def update_final_layer_weights(self, new_weights):
        sample_input = tf.random.uniform((1, new_weights[0].shape[0]))
        _ = self.final_layer(sample_input)
        old_weights = self.final_layer.get_weights()
        print(f"Old Weights Shape: {[w.shape for w in old_weights]}")
        if len(new_weights) == 2:
            self.final_layer.set_weights(new_weights)
            print("âœ… Final layer weights updated successfully!")
        else:
            raise ValueError("New weights must be a list of [kernel, bias]")

    def call(self, inp, tar, *, training=False, enc_padding_mask=None,
             look_ahead_mask=None, dec_padding_mask=None):
        enc_output = self.encoder(x=inp, training=training, mask=enc_padding_mask)
        dec_output, attention_weights = self.decoder(
            x=tar, enc_output=enc_output, training=training,
            look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask
        )
        final_output = self.final_layer(dec_output)
        return final_output, attention_weights


#----------------------------------------------------------------------------------------------



#---------------------------------------------------------------------------------------------

# num_layers =6
# d_model = 128
# dff = 512
# num_heads = 8
# dropout_rate = 0.3
# EPOCHS = 90

num_layers = 3
# d_model = 256
d_model=256
dff = 512
num_heads = 8
dropout_rate = 0.2
EPOCHS = 200
num_experts=2


class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
    def __init__(self, d_model, warmup_steps=4000):
        super(CustomSchedule, self).__init__()

        self.d_model = d_model
        self.d_model = tf.cast(self.d_model, tf.float32)

        self.warmup_steps = warmup_steps


    def __call__(self, step):
        step = tf.cast(step, dtype=tf.float32)
        arg1 = tf.math.rsqrt(step)
        arg2 = step * (self.warmup_steps ** -1.5)

        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)


learning_rate = CustomSchedule(d_model)
# learning_rate=.01
# learning_rate=.0001

optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)
temp_learning_rate_schedule = CustomSchedule(d_model)

plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))
plt.ylabel("Learning Rate")
plt.xlabel("Train Step")


# -------------------------------------- changed for retention-------------------------------------

loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')
def loss_function(real, pred):
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    loss_ = loss_object(real, pred)

    mask = tf.cast(mask, dtype=loss_.dtype)
    loss_ *= mask

    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)


def accuracy_function(real, pred):
    # accuracies = tf.equal(real, tf.argmax(pred, axis=2))
    # accuracies = tf.cast(accuracies, dtype= tf.float32)
    # mask = tf.math.logical_not(tf.math.equal(real, 0))
    # # accuracies = tf.math.logical_and(mask, accuracies)
    # accuracies = tf.cast(accuracies, dtype=tf.float32)
    # mask = tf.cast(mask, dtype=tf.float32)
    # return tf.reduce_sum(accuracies) / tf.reduce_sum(mask
    accuracies = tf.equal(real, tf.argmax(pred, axis=2))
    accuracies = tf.cast(accuracies, dtype= tf.float32)
    mask = tf.math.logical_not(tf.math.equal(real, 0))
    # accuracies = tf.math.logical_and(mask, accuracies)
    accuracies = tf.cast(accuracies, dtype=tf.float32)
    mask = tf.cast(mask, dtype=tf.float32)
    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)

    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)

train_loss = tf.keras.metrics.Mean(name='train_loss')
train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')



transformer = Transformer(
    num_layers=num_layers,
    d_model=d_model,
    num_heads=num_heads,
    dff=dff,
    input_vocab_size=ENCODER_VOCAB,
    target_vocab_size=DECODER_VOCAB,
    pe_input=1000,
    pe_target=1000,
    rate=dropout_rate)

new_kernel = tf.random.normal((128, DECODER_VOCAB))  # Shape: (input_dim, output_dim)
new_bias = tf.zeros((DECODER_VOCAB,))                # Shape: (output_dim,)
new_weights = [new_kernel, new_bias]

def create_masks(inp, tar):
    enc_padding_mask = create_padding_mask(inp)
    dec_padding_mask = create_padding_mask(inp)

    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])
    dec_target_padding_mask = create_padding_mask(tar)
    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)

    return enc_padding_mask, combined_mask, dec_padding_mask

checkpoint_path = "/kaggle/working/checkpoint1"
ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)
ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)

if ckpt_manager.latest_checkpoint:
    ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()


    #     # Freeze the first encoder and decoder layers
    # for layer in transformer.layers:
    #     layer.trainable = True
    #     if isinstance(layer, Encoder):
    #         layer.embedding.trainable = False
    #         # layer.dropout.trainable = False
    #     if isinstance(layer, Decoder):
    #         layer.embedding.trainable = False
    # for enc_layer in transformer.encoder.enc_layers[:1]:
    #     enc_layer.trainable = False
    #     if hasattr(enc_layer, "mha"):
    #         enc_layer.mha.trainable = False
    #     if hasattr(enc_layer, "ffn"):
    #         enc_layer.ffn.trainable = False
    #         print(f"  - Freezing Encoder FFN: {enc_layer.ffn.name}, Trainable: {enc_layer.ffn.trainable}")
    #
    # # Freeze first decoder layer
    # for dec_layer in transformer.decoder.dec_layers[:2]:
    #     print("sssssssssssssssssssssssss")
    #     dec_layer.trainable = False
    #
    #     if hasattr(dec_layer, "mha1"):
    #         dec_layer.mha1.trainable = False
    #
    #     if hasattr(dec_layer, "mha2"):
    #         dec_layer.mha2.trainable = False
    #         print(f"  - Freezing Decoder MHA2: {dec_layer.mha2.name}, Trainable: {dec_layer.mha2.trainable}")
    #
    #     if hasattr(dec_layer, "ffn"):
    #         dec_layer.ffn.trainable = False
    #         print(f"  - Freezing Decoder FFN: {dec_layer.ffn.name}, Trainable: {dec_layer.ffn.trainable}")
    #
    # # Set remaining encoder layers to trainable
    # for enc_layer in transformer.encoder.enc_layers[2:]:
    #     print("fffffffffffffffffffffff")
    #     enc_layer.trainable = True
    #     print(f"Training Encoder Layer: {enc_layer.name}, Trainable: {enc_layer.trainable}")
    #
    #     # Set remaining decoder layers to trainable
    #     for dec_layer in transformer.decoder.dec_layers[2:]:
    #         dec_layer.trainable = True
    #         print(f"Training Decoder Layer: {dec_layer.name}, Trainable: {dec_layer.trainable}")
    #
    #     print("âœ… Latest checkpoint restored!")
    print("âœ… Latest checkpoint restored!")

@tf.function
def train_step(inp, tar):
    tar_inp = tar[:, :-1]
    tar_real = tar[:, 1:]

    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)

    with tf.GradientTape() as tape:
        # predictions, _ = transformer(
        #     inp,
        #     tar_inp,
        #     training=True,
        #     enc_padding_mask=enc_padding_mask,
        #     look_ahead_mask=combined_mask,
        #     dec_padding_mask=dec_padding_mask
        # )
        predictions, _ = transformer(
        inp=inp,
        tar=tar_inp,
        training=True,
        enc_padding_mask=enc_padding_mask,
        look_ahead_mask=combined_mask,
        dec_padding_mask=enc_padding_mask
    )


        loss = loss_function(tar_real, predictions)

    gradients = tape.gradient(loss, transformer.trainable_variables)
    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))
    train_loss(loss)
    train_accuracy(accuracy_function(tar_real, predictions))
import tarfile

for epoch in range(EPOCHS):
    start = time.time()

    train_loss.reset_state()

    for (batch, (inp, tar)) in enumerate(dataset):
        train_step(inp, tar)
        if batch % 100 == 0:
            print(
                f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')
    # for i, enc_layer in enumerate(transformer.encoder.enc_layers):
    #     print(f"Encoder Layer {i} Weights:")
    #     for weight in enc_layer.weights:
    #         print(f" - {weight.name}, Shape: {weight.shape}")
    if (epoch == 196):
        # ckpt_save_path = ckpt_manager.save()
        # print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))
        ckpt_save_path = "/kaggle/working/checkpoints1"
        print(epoch)

        # Create a new CheckpointManager for the new location
        savepoint = tf.train.CheckpointManager(ckpt, ckpt_save_path, max_to_keep=3)

        # Save checkpoint
        savepoint.save()


    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')
    print('Time taken for 1 epoch: {} secs\n'.format(time.time() - start))

# ckpt_save_path = "/kaggle/working"

# savepoint = tf.train.CheckpointManager(ckpt, ckpt_save_path, max_to_keep=5)

# for epoch in range(EPOCHS):
#     start = time.time()

#     train_loss.reset_state()

#     for (batch, (inp, tar)) in enumerate(dataset):
#         train_step(inp, tar)
#         if batch % 100 == 0:
#             print(
#                 f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')
#     if epoch == EPOCHS - 1:

#         # Create a new CheckpointManager for the new location

#         # Save checkpoint
#         ckpt_path=savepoint.save()
#         archive_path = "/kaggle/working/checkpoints.tar"
#         with tarfile.open(archive_path, "w") as tar:
#             tar.add(ckpt_save_path, arcname=os.path.basename(ckpt_save_path))
#         print(f"ðŸ“¦ Checkpoint archived: {archive_path}")

def evaluate(input_article):
    # Tokenize and pad the input article
    print(input_article)
    input_article = re.sub(r'(\d)', r'\1 ', input_article)  # Adds space after each digit
    input_article = input_article.replace("  ", " ").strip()

    input_article = tf.convert_to_tensor(input_article, dtype=tf.string)  # Ensure it's a TensorFlow string
    input_article = input_article.numpy().decode("utf-8")
    input_article = article_tokenizer.texts_to_sequences([input_article])
    print("tokens")
    print(input_article)

    input_article = tf.keras.preprocessing.sequence.pad_sequences(
        input_article, maxlen=ENCODER_LEN, padding='post', truncating='post'
    )
    print("Inputs")
    print(input_article)
    encoder_input = tf.expand_dims(input_article[0], 0)
    print (encoder_input)
    decoder_input = [summary_tokenizer.word_index['<sos>']]
    output = tf.expand_dims(decoder_input, 0)

    for i in range(DECODER_LEN):
        # Create masks
        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)

        # Get predictions from the transformer
        predictions, attention_weights = transformer(
            encoder_input,
            output,
            training=False,
            enc_padding_mask=enc_padding_mask,
            look_ahead_mask=combined_mask,
            dec_padding_mask=dec_padding_mask
        )
        predictions = predictions[:, -1:, :]  # Take the last predicted token
        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)
        if predicted_id == summary_tokenizer.word_index['<eos>']:
            return tf.squeeze(output, axis=0), attention_weights
        # Append the predicted token to the output
        output = tf.concat([output, predicted_id], axis=-1)
    return tf.squeeze(output, axis=0), attention_weights

def summarize(input_article):
    summarized = evaluate(input_article=input_article)[0].numpy()
    summarized = np.expand_dims(summarized[1:], 0)  # Remove the <sos> token
    return summary_tokenizer.sequences_to_texts(summarized)[0]

# Test the function
print('Output:')
print(summarize(
    'Visual Studio Code & C programming on Linux'))
def preprocess_and_split_numbers(input_text):
    # Split numbers into their individual digits
    # This regular expression finds numbers and splits them into individual characters
    input_text = re.sub(r'(\d)', r' \1 ', input_text)  # Add space around each digit
    return input_text
