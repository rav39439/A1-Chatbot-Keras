import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import pandas as pd
# from collections import defaultdict
# import string
# import tensorflow as tf
# import re
# import os
# import time
# from tensorflow import keras
# from tensorflow.keras.layers import Dense, Input
# from tensorflow.keras.optimizers import Adam
# from tensorflow.keras.models import Model
# from tensorflow.keras.callbacks import ModelCheckpoint
# from sklearn.preprocessing import OneHotEncoder
# from sklearn.model_selection import train_test_split
# ENCODER_LEN = 200
# DECODER_LEN = 100
# BATCH_SIZE = 64
# BUFFER_SIZE = BATCH_SIZE*8
# # news = pd.read_csv("samples1.csv")
# # ----------------------------------one way--------------------------------------------------
# 
# 
# 
# # --------------------------------------proccessing numbers-----------------------------------
# 
# 
# news = pd.read_csv("addition_samples.csv")  # Replace with your file path
# article = news['Input']
# summary = news['Output']
# 
# # Add SOS and EOS tokens
# article = article.apply(lambda x: '<SOS> ' + str(x) + ' <EOS>')
# summary = summary.apply(lambda x: '<SOS> ' + str(x) + ' <EOS>')
# 
# def preprocess(text):
#     # Tokenize numbers and separate them into digits
#     text = re.sub(r'(\d+)', lambda match: ' '.join(list(match.group(0))), text)  # e.g., "64" → "6 4"
# 
#     # Add spaces around operators for proper tokenization
#     text = re.sub(r"(\+|\-|\*|/|=)", r" \1 ", text)  # Add spaces around operators
# 
#     # Tokenize spaces between words
#     text = re.sub(r'\s+', ' ', text).strip()  # Normalize spaces
# 
#     # Make text lowercase
#     text = text.lower()
# 
#     return text
# # Apply preprocessing
# article = article.apply(preprocess)
# summary = summary.apply(preprocess)
# # summary = summary.apply(lambda x: ' '.join(x.split()[:-3]))
# 
# filters = '₹!"#$%&()-.:;?@[\\]^_`{|}~\t\n,'  # Ensure ',' is inside the quotes
# 
# # filters = '₹!"#$%&(),-./:;=?@[\\]^_`{|}~\t\n'
# 
# oov_token = '<unk>'
# 
# article_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)
# summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)
# 
# # Fit tokenizers on preprocessed data
# article_tokenizer.fit_on_texts(article)
# summary_tokenizer.fit_on_texts(summary)
# if ',' not in article_tokenizer.word_index:
#     article_tokenizer.word_index[','] = len(article_tokenizer.word_index) + 1
# 
# if ',' not in summary_tokenizer.word_index:
#     summary_tokenizer.word_index[','] = len(summary_tokenizer.word_index) + 1
# # Convert text to sequences
# inputs = article_tokenizer.texts_to_sequences(article)
# targets = summary_tokenizer.texts_to_sequences(summary)
# # print(inputs)
# 
# # Vocabulary sizes
# ENCODER_VOCAB = len(article_tokenizer.word_index) + 1
# DECODER_VOCAB = len(summary_tokenizer.word_index) + 1
# top_k=4
# # Pad sequences
# ENCODER_LEN = 70  # Maximum length of input sequences
# DECODER_LEN = 40   # Maximum length of output sequences
# 
# inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=ENCODER_LEN, padding='post', truncating='post')
# targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=DECODER_LEN, padding='post', truncating='post')
# input_texts_padded = [' '.join([article_tokenizer.index_word.get(token, '') for token in seq]) for seq in inputs]
# target_texts_padded = [' '.join([summary_tokenizer.index_word.get(token, '') for token in seq]) for seq in targets]
# 
# # Print tokenizers' word index
# print("Article Tokenizer Word Index (Word to Token):")
# print(article_tokenizer.word_index)
# print("\nSummary Tokenizer Word Index (Word to Token):")
# print(summary_tokenizer.word_index)
# word_43 = article_tokenizer.index_word.get(43, "Not found")
# word_35 = article_tokenizer.index_word.get(35, "Not found")
# word_72 = summary_tokenizer.index_word.get(35, "Not found")
# inputs = tf.cast(inputs, dtype=tf.int64)
# targets = tf.cast(targets, dtype=tf.int64)
# dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
# 
# 
# 
# # -------------------------------------------------------------------------------------------
# 
# 
# # --------------------------transformer---------------------------------------
# import tensorflow as tf
# from tensorflow.keras.layers import Dense, Layer, Dropout, LayerNormalization
# 
# 
# class MoELayer(Layer):
#     def __init__(self, d_model, d_ff, num_experts=4, top_k=2, dropout_rate=0.1):
#         """
#         d_model: Model embedding size
#         d_ff: Hidden layer size for FFN
#         num_experts: Number of expert FFNs
#         top_k: Number of experts selected per token
#         dropout_rate: Dropout rate for regularization
#         """
#         super(MoELayer, self).__init__()
#         self.num_experts = num_experts
#         self.top_k = top_k
# 
#         # Define multiple FFN experts
#         self.experts = [Dense(d_ff, activation="relu") for _ in range(num_experts)]
#         self.output_layer = Dense(d_model)  # Final projection back to d_model
#         self.dropout = Dropout(dropout_rate)
#         self.layer_norm = LayerNormalization()
# 
#         # Router to decide which experts to activate
#         self.router = Dense(num_experts, activation="softmax")  # Output is routing weights
# 
#     def call(self, x):
#         batch_size, seq_len, d_model = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2]
# 
#         # Compute routing weights for each token
#         routing_logits = self.router(x)  # Shape: (batch_size, seq_len, num_experts)
# 
#         # Select top-k experts based on highest routing weights
#         top_k_values, top_k_indices = tf.math.top_k(routing_logits, k=self.top_k)  # (batch_size, seq_len, top_k)
# 
#         # Normalize routing weights (softmax over selected experts)
#         routing_weights = tf.nn.softmax(top_k_values, axis=-1)  # (batch_size, seq_len, top_k)
# 
#         # Compute outputs from selected experts
#         expert_outputs = tf.stack([self.experts[i](x) for i in range(self.num_experts)], axis=-1)
#         # Shape: (batch_size, seq_len, d_ff, num_experts)
# 
#         # Gather selected experts' outputs
#         selected_expert_outputs = tf.gather(expert_outputs, top_k_indices, batch_dims=-1, axis=-1)
#         # Shape: (batch_size, seq_len, d_ff, top_k)
# 
#         # Weighted sum of top-k expert outputs
#         weighted_expert_output = tf.reduce_sum(selected_expert_outputs * tf.expand_dims(routing_weights, -2), axis=-1)
#         # Shape: (batch_size, seq_len, d_ff)
# 
#         # Final projection back to d_model
#         output = self.output_layer(weighted_expert_output)
#         return self.layer_norm(x + self.dropout(output))  # Residual connection
# 
# class SwitchLayer(tf.keras.layers.Layer):
#     def __init__(self, num_experts, d_model):
#         super(SwitchLayer, self).__init__()
#         self.experts = [tf.keras.layers.Dense(d_model) for _ in range(num_experts)]
# 
#     def call(self, x):
#         # Route based on some condition (e.g., token type)
#         condition = tf.reduce_mean(x, axis=-1) > 0
#         output = tf.where(condition[:, tf.newaxis], self.experts[0](x), self.experts[1](x))
#         return output
# 
# #--------------------------------------------------------------------------------------
# 
# """
# ## Implement a Transformer block layer
# """
# 
# def get_angles(position, i, d_model):
#     angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
#     return position * angle_rates
# 
# def positional_encoding(position, d_model):
#     angle_rads = get_angles(
#         np.arange(position)[:, np.newaxis],
#         np.arange(d_model)[np.newaxis, :],
#         d_model
#     )
# 
#     angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
# 
#     angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
# 
#     pos_encoding = angle_rads[np.newaxis, ...]
# 
#     return tf.cast(pos_encoding, dtype=tf.float32)
# 
# def create_padding_mask(seq):
#     seq = tf.cast(tf.math.equal(seq, 0), tf.float32)
#     return seq[:, tf.newaxis, tf.newaxis, :]
# 
# def create_look_ahead_mask(size):
#     mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)
#     return mask
# 
# def scaled_dot_product_attention(q, k, v, mask):
#     matmul_qk = tf.matmul(q, k, transpose_b=True)
# 
#     dk = tf.cast(tf.shape(k)[-1], tf.float32)
#     scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)
#     if mask is not None:
#         scaled_attention_logits += (mask * -1e9)
# 
#     attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
# 
#     output = tf.matmul(attention_weights, v)
#     return output, attention_weights
# 
# 
# class MultiHeadAttention(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads):
#         super(MultiHeadAttention, self).__init__()
#         self.num_heads = num_heads
#         self.d_model = d_model
# 
#         assert d_model % self.num_heads == 0
# 
#         self.depth = d_model // self.num_heads
# 
#         self.wq = tf.keras.layers.Dense(d_model)
#         self.wk = tf.keras.layers.Dense(d_model)
#         self.wv = tf.keras.layers.Dense(d_model)
# 
#         self.dense = tf.keras.layers.Dense(d_model)
# 
#     def split_heads(self, x, batch_size):
#         x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
#         return tf.transpose(x, perm=[0, 2, 1, 3])
# 
#     def call(self, v, k, q, mask):
#         batch_size = tf.shape(q)[0]
# 
#         q = self.wq(q)
#         k = self.wk(k)
#         v = self.wv(v)
# 
#         q = self.split_heads(q, batch_size)
#         k = self.split_heads(k, batch_size)
#         v = self.split_heads(v, batch_size)
# 
#         scaled_attention, attention_weights = scaled_dot_product_attention(
#             q, k, v, mask)
#         scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])
# 
#         concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))
#         output = self.dense(concat_attention)
#         return output, attention_weights
# 
# 
# def point_wise_feed_forward_network(d_model, dff):
#     return tf.keras.Sequential([
#         tf.keras.layers.Dense(dff, activation='relu'),
#         tf.keras.layers.Dense(d_model)
#     ])
# 
# #----------------------------------------------------------------------------------------------
# class EncoderLayer(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads, dff, shared_attention=None, rate=0.1):
#         super(EncoderLayer, self).__init__()
#         self.mha = shared_attention if shared_attention else MultiHeadAttention(d_model, num_heads)
#         self.ffn = point_wise_feed_forward_network(d_model, dff)
#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
# 
#         self.dropout1 = tf.keras.layers.Dropout(rate)
#         self.dropout2 = tf.keras.layers.Dropout(rate)
# 
#     def call(self, x, training, mask):
#         attn_output, _ = self.mha(x, x, x, mask)
#         attn_output = self.dropout1(attn_output, training=training)
#         out1 = self.layernorm1(x + attn_output)
#         ffn_output = self.ffn(out1)
#         ffn_output = self.dropout2(ffn_output, training=training)
#         out2 = self.layernorm2(out1 + ffn_output)
#         return out2
# 
# 
# class DecoderLayer(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads, dff, shared_attention=None, rate=0.1):
#         super(DecoderLayer, self).__init__()
#         self.mha1 = shared_attention if shared_attention else MultiHeadAttention(d_model, num_heads)
#         self.mha2 = MultiHeadAttention(d_model, num_heads)
#         self.ffn = point_wise_feed_forward_network(d_model, dff)
# 
#         self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
#         self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
# 
#         self.dropout1 = tf.keras.layers.Dropout(rate)
#         self.dropout2 = tf.keras.layers.Dropout(rate)
#         self.dropout3 = tf.keras.layers.Dropout(rate)
# 
#     def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
#         attn1, _ = self.mha1(x, x, x, look_ahead_mask)
#         attn1 = self.dropout1(attn1, training=training)
#         out1 = self.layernorm1(x + attn1)
# 
#         attn2, _ = self.mha2(enc_output, enc_output, out1, padding_mask)
#         attn2 = self.dropout2(attn2, training=training)
#         out2 = self.layernorm2(attn2 + out1)
# 
#         ffn_output = self.ffn(out2)
#         ffn_output = self.dropout3(ffn_output, training=training)
#         out3 = self.layernorm3(out2 + ffn_output)
#         return out3
# 
# class Encoder(tf.keras.layers.Layer):
#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, max_pos_encoding, shared_attention=None, rate=0.1):
#         super(Encoder, self).__init__()
#         self.d_model = d_model
#         self.num_layers = num_layers
#         self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)
#         self.pos_encoding = positional_encoding(max_pos_encoding, self.d_model)
# 
#         self.enc_layers = [EncoderLayer(d_model, num_heads, dff, shared_attention, rate) for _ in range(num_layers)]
#         self.dropout = tf.keras.layers.Dropout(rate)
# 
#     def call(self, x, training, mask):
#         seq_len = tf.shape(x)[1]
#         x = self.embedding(x)
#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
#         x += self.pos_encoding[:, :seq_len, :]
# 
#         x = self.dropout(x, training=training)
# 
#         for i in range(self.num_layers):
#             x = self.enc_layers[i](x, training, mask)
# 
#         return x
# 
# class Decoder(tf.keras.layers.Layer):
#     def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, max_pos_encoding, shared_attention=None, rate=0.1):
#         super(Decoder, self).__init__()
#         self.d_model = d_model
#         self.num_layers = num_layers
# 
#         self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)
#         self.pos_encoding = positional_encoding(max_pos_encoding, d_model)
# 
#         self.dec_layers = [DecoderLayer(d_model, num_heads, dff, shared_attention, rate) for _ in range(num_layers)]
#         self.dropout = tf.keras.layers.Dropout(rate)
# 
#     def call(self, x, enc_output, training, look_ahead_mask, padding_mask):
#         seq_len = tf.shape(x)[1]
#         attention_weights = {}
# 
#         x = self.embedding(x)
#         x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))
#         x += self.pos_encoding[:, :seq_len, :]
# 
#         x = self.dropout(x, training=training)
# 
#         for i in range(self.num_layers):
#             x = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)
# 
#         return x, attention_weights
# 
# 
# class Transformer(tf.keras.Model):
#     def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target,shared_attention=None,
#                  rate=0.1):
#         super(Transformer, self).__init__()
#         shared_attention = MultiHeadAttention(d_model, num_heads)
#         self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, shared_attention, rate)
#         self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, shared_attention,
#                                rate)
#         self.final_layer = tf.keras.layers.Dense(target_vocab_size)
# 
#     def compute_distillation_loss(self, student_logits, teacher_logits, temperature=1.0):
#         student_probs = tf.nn.softmax(student_logits / temperature)
#         teacher_probs = tf.nn.softmax(teacher_logits / temperature)
#         loss = tf.reduce_mean(tf.keras.losses.KLDivergence()(teacher_probs, student_probs))
#         return loss
# 
#     def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask, teacher_logits=None):
#         enc_output = self.encoder(inp, training, enc_padding_mask)
#         dec_output, atten = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)
#         final_output = self.final_layer(dec_output)
#         if teacher_logits is not None:
#             distillation_loss = self.compute_distillation_loss(final_output, teacher_logits)
#             self.add_loss(distillation_loss)
# 
#         return final_output,atten
# 
# 
# #---------------------------------------------------------------------------------------------
# 
# # num_layers = 6
# # d_model = 128
# # dff = 512
# # num_heads = 8
# # dropout_rate = 0.3
# # EPOCHS = 90
# 
# num_layers = 3
# # d_model = 128
# d_model=128
# dff = 256
# num_heads = 4
# dropout_rate = 0.2
# EPOCHS = 5
# num_experts=2
# 
# 
# class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):
#     def __init__(self, d_model, warmup_steps=4000):
#         super(CustomSchedule, self).__init__()
# 
#         self.d_model = d_model
#         self.d_model = tf.cast(self.d_model, tf.float32)
# 
#         self.warmup_steps = warmup_steps
# 
# 
#     def __call__(self, step):
#         step = tf.cast(step, dtype=tf.float32)
#         arg1 = tf.math.rsqrt(step)
#         arg2 = step * (self.warmup_steps ** -1.5)
# 
#         return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)
# 
# 
# learning_rate = CustomSchedule(d_model)
# # learning_rate=.01
# 
# optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)
# temp_learning_rate_schedule = CustomSchedule(d_model)
# 
# plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))
# plt.ylabel("Learning Rate")
# plt.xlabel("Train Step")
# 
# distillation_loss_object = tf.keras.losses.KLDivergence()
# student_loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')
# 
# 
# def distillation_loss_function(real, student_logits, teacher_logits, alpha=0.5, temperature=1.0):
#     # Student loss (standard transformer loss)
#     mask = tf.math.logical_not(tf.math.equal(real, 0))
#     # print(real)
#     # print(student_logits)
#     # print(teacher_logits)
#     # print(
#     #     f"Real shape: {real.shape}, Student logits shape: {student_logits.shape}, Teacher logits shape: {teacher_logits.shape}")
# 
#     student_logits = tf.convert_to_tensor(student_logits, dtype=tf.float32)
#     teacher_logits = tf.convert_to_tensor(teacher_logits, dtype=tf.float32)
#     student_loss = student_loss_object(real, student_logits)
#     # print(student_loss)
#     mask = tf.cast(mask, dtype=student_loss.dtype)
#     student_loss *= mask
# 
#     # Distillation loss (KL Divergence)
#     teacher_logits = tf.nn.softmax(teacher_logits / temperature, axis=-1)
#     student_logits = tf.nn.softmax(student_logits / temperature, axis=-1)
#     distillation_loss = distillation_loss_object(teacher_logits, student_logits)
# 
#     # Combine student loss and distillation loss
#     total_loss = alpha * distillation_loss + (1 - alpha) * tf.reduce_sum(student_loss) / tf.reduce_sum(mask)
#     return total_loss
# 
# 
# def accuracy_function(real, pred):
#     accuracies = tf.equal(real, tf.argmax(pred, axis=2))
#     accuracies = tf.cast(accuracies, dtype=tf.float32)
#     mask = tf.math.logical_not(tf.math.equal(real, 0))
#     mask = tf.cast(mask, dtype=tf.float32)
#     return tf.reduce_sum(accuracies * mask) / tf.reduce_sum(mask)
# 
# 
# train_loss = tf.keras.metrics.Mean(name='train_loss')
# train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')
# 
# 
# # -------------------
# # Expert Weight Sharing (EWS)
# # -------------------
# class ExpertLayer(tf.keras.layers.Layer):
#     def __init__(self, d_model, num_heads):
#         super(ExpertLayer, self).__init__()
#         self.shared_attention = MultiHeadAttention(d_model, num_heads)
# 
#     def call(self, x, training, mask):
#         return self.shared_attention(x, x, x, mask)
# 
# shared_attention = ExpertLayer(d_model, num_heads)
# 
# 
# def create_masks(inp, tar):
#     enc_padding_mask = create_padding_mask(inp)
#     dec_padding_mask = create_padding_mask(inp)
# 
#     look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])
#     dec_target_padding_mask = create_padding_mask(tar)
#     combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)
# 
#     return enc_padding_mask, combined_mask, dec_padding_mask
# # -------------------
# transformer = Transformer(
#     num_layers=num_layers,
#     d_model=d_model,
#     num_heads=num_heads,
#     dff=dff,
#     input_vocab_size=ENCODER_VOCAB,
#     target_vocab_size=DECODER_VOCAB,
#     pe_input=1000,
#     pe_target=1000,
#     rate=dropout_rate,
#     shared_attention=shared_attention
# )
# 
# # -------------------
# # Teacher Model (for Knowledge Distillation)
# # -------------------
# teacher_transformer = Transformer(
#     num_layers=num_layers,
#     d_model=d_model,
#     num_heads=num_heads,
#     dff=dff,
#     input_vocab_size=ENCODER_VOCAB,
#     target_vocab_size=DECODER_VOCAB,
#     pe_input=1000,
#     pe_target=1000,
#     rate=dropout_rate
# )
# 
# # -------------------
# # Training Step with KD and EWS
# # -------------------
# # @tf.function
# def train_step(inp, tar):
#     tar_inp = tar[:, :-1]
#     tar_real = tar[:, 1:]
# 
#     enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)
# 
#     with tf.GradientTape() as tape:
#         # Get teacher logits
#         teacher_logits,atten = teacher_transformer(
#             inp,
#             tar_inp,
#             training=False,
#             enc_padding_mask=enc_padding_mask,
#             look_ahead_mask=combined_mask,
#             dec_padding_mask=dec_padding_mask
#         )
# 
#         # Get student logits (with shared attention)
#         student_logits,atten = transformer(
#             inp,
#             tar_inp,
#             training=True,
#             enc_padding_mask=enc_padding_mask,
#             look_ahead_mask=combined_mask,
#             dec_padding_mask=dec_padding_mask
#         )
# 
#         # Compute combined distillation + student loss
#         loss = distillation_loss_function(tar_real, student_logits, teacher_logits, alpha=0.5, temperature=1.0)
#     # Apply gradients
#     #     print(transformer.trainable_variables)
#     # print("Loss:", loss.numpy())  # If using eager execution
#     gradients = tape.gradient(loss, transformer.trainable_variables)
#     optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))
# 
#     train_loss(loss)
#     train_accuracy(accuracy_function(tar_real, student_logits))
# 
# # -------------------
# # Checkpoints
# # -------------------
# checkpoint_path = "checkpoints"
# ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)
# ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)
# 
# if ckpt_manager.latest_checkpoint:
#     ckpt.restore(ckpt_manager.latest_checkpoint).expect_partial()
#     for layer in teacher_transformer.layers:
#         layer.trainable = False
#         if isinstance(layer, Encoder):
#             # print(f"   - Embedding: {layer.embedding.name}, Trainable: {layer.embedding.trainable}")
#             layer.embedding.trainable = False
#             layer.dropout.trainable = False
#             for i, enc_layer in enumerate(layer.enc_layers):
#                 enc_layer.trainable = False
#                 if hasattr(enc_layer, "mha"):
#                     enc_layer.mha.trainable = False
#                 if hasattr(enc_layer, "ffn"):
#                     enc_layer.ffn.trainable = False
# 
#         if isinstance(layer, Decoder):
#             layer.embedding.trainable = False
#             for i, dec_layer in enumerate(layer.dec_layers):
#                 dec_layer.trainable = False
#                 layer.dropout.trainable = False
#                 if hasattr(dec_layer, "mha1"):
#                     dec_layer.mha1.trainable = False
# 
#                 if hasattr(dec_layer, "mha2"):
#                     dec_layer.mha2.trainable = False
# 
#                 if hasattr(dec_layer, "ffn"):
#                     dec_layer.ffn.trainable = False
# 
#             # Freeze final Dense layer
#         if isinstance(layer, tf.keras.layers.Dense):
#             print(f" - Freezing Final Dense Layer: {layer.name}, Trainable: {layer.trainable}")
#             layer.trainable = False
# 
#     # Freeze the first encoder and decoder layers
#     for layer in transformer.layers:
#         layer.trainable = True
#         if isinstance(layer, Encoder):
#             layer.embedding.trainable = False
#             # layer.dropout.trainable = False
#         if isinstance(layer, Decoder):
#             layer.embedding.trainable = False
#     for enc_layer in transformer.encoder.enc_layers[:1]:
#         enc_layer.trainable = False
#         if hasattr(enc_layer, "mha"):
#             enc_layer.mha.trainable = False
#         if hasattr(enc_layer, "ffn"):
#             enc_layer.ffn.trainable = False
#             print(f"  - Freezing Encoder FFN: {enc_layer.ffn.name}, Trainable: {enc_layer.ffn.trainable}")
# 
#     # Freeze first decoder layer
#     for dec_layer in transformer.decoder.dec_layers[:1]:
#         dec_layer.trainable = False
# 
#         if hasattr(dec_layer, "mha1"):
#             dec_layer.mha1.trainable = False
# 
#         if hasattr(dec_layer, "mha2"):
#             dec_layer.mha2.trainable = False
#             print(f"  - Freezing Decoder MHA2: {dec_layer.mha2.name}, Trainable: {dec_layer.mha2.trainable}")
# 
#         if hasattr(dec_layer, "ffn"):
#             dec_layer.ffn.trainable = False
#             print(f"  - Freezing Decoder FFN: {dec_layer.ffn.name}, Trainable: {dec_layer.ffn.trainable}")
# 
#     # Set remaining encoder layers to trainable
#     for enc_layer in transformer.encoder.enc_layers[1:]:
#         enc_layer.trainable = True
#         print(f"Training Encoder Layer: {enc_layer.name}, Trainable: {enc_layer.trainable}")
# 
#     # Set remaining decoder layers to trainable
#     for dec_layer in transformer.decoder.dec_layers[1:]:
#         dec_layer.trainable = True
#         print(f"Training Decoder Layer: {dec_layer.name}, Trainable: {dec_layer.trainable}")
# 
#     print("✅ Latest checkpoint restored!")
# 
# for epoch in range(EPOCHS):
#     start = time.time()
# 
#     train_loss.reset_states()
# 
#     for (batch, (inp, tar)) in enumerate(dataset):
#         train_step(inp, tar)
#         if batch % 100 == 0:
#             print(
#                 f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')
# 
#     if (epoch + 1) % 5 == 0:
#         # ckpt_save_path = ckpt_manager.save()
#         ckpt_save_path = "checkpoints1"
# 
#         # Create a new CheckpointManager for the new location
#         savepoint = tf.train.CheckpointManager(ckpt, ckpt_save_path, max_to_keep=5)
# 
#         # Save checkpoint
#         savepoint.save()
# 
#         ckpt_save_path1 = "checkpoints2"
#         ckpt1 = tf.train.Checkpoint(transformer=teacher_transformer, optimizer=optimizer)
# 
#         # Create a new CheckpointManager for the new location
#         savepoint1 = tf.train.CheckpointManager(ckpt1, ckpt_save_path1, max_to_keep=5)
# 
#         # Save checkpoint
#         savepoint1.save()
# 
#         print('Saving checkpoint for epoch {} at {}'.format(epoch + 1, ckpt_save_path))
# 
#     print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')
#     print('Time taken for 1 epoch: {} secs\n'.format(time.time() - start))
# 
# 
# 
# #---------------------------------------------------------------------------------------
# 
# 
# #--------------------------------------------------------------------------------------------------
# 
# def evaluate(input_article):
#     # Tokenize and pad the input article
#     print(input_article)
#     input_article = re.sub(r'(\d)', r'\1 ', input_article)  # Adds space after each digit
#     input_article = input_article.replace("  ", " ").strip()
# 
#     input_article = tf.convert_to_tensor(input_article, dtype=tf.string)  # Ensure it's a TensorFlow string
#     input_article = input_article.numpy().decode("utf-8")
#     input_article = article_tokenizer.texts_to_sequences([input_article])
#     print("tokens")
#     print(input_article)
# 
#     input_article = tf.keras.preprocessing.sequence.pad_sequences(
#         input_article, maxlen=ENCODER_LEN, padding='post', truncating='post'
#     )
#     print("Inputs")
#     print(input_article)
#     encoder_input = tf.expand_dims(input_article[0], 0)
#     print (encoder_input)
#     decoder_input = [summary_tokenizer.word_index['<sos>']]
#     output = tf.expand_dims(decoder_input, 0)
# 
#     for i in range(DECODER_LEN):
#         # Create masks
#         enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)
# 
#         # Get predictions from the transformer
#         predictions, attention_weights = transformer(
#             encoder_input,
#             output,
#             training=False,
#             enc_padding_mask=enc_padding_mask,
#             look_ahead_mask=combined_mask,
#             dec_padding_mask=dec_padding_mask
#         )
#         predictions = predictions[:, -1:, :]  # Take the last predicted token
#         predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)
#         if predicted_id == summary_tokenizer.word_index['<eos>']:
#             return tf.squeeze(output, axis=0), attention_weights
#         # Append the predicted token to the output
#         output = tf.concat([output, predicted_id], axis=-1)
#     return tf.squeeze(output, axis=0), attention_weights
# 
# def summarize(input_article):
#     summarized = evaluate(input_article=input_article)[0].numpy()
#     summarized = np.expand_dims(summarized[1:], 0)  # Remove the <sos> token
#     return summary_tokenizer.sequences_to_texts(summarized)[0]
# 
# # Test the function
# print('Output:')
# print(summarize(
#     '<SOS> Calculate the average of 28 and 67 and 86 <EOS>'))
# def preprocess_and_split_numbers(input_text):
#     # Split numbers into their individual digits
#     # This regular expression finds numbers and splits them into individual characters
#     input_text = re.sub(r'(\d)', r' \1 ', input_text)  # Add space around each digit
#     return input_text